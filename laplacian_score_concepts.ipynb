{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b4cd3454",
   "metadata": {},
   "source": [
    "## Introduction to Laplacian Based Feature Selection for Unlabeled Dataset\n",
    "### Author - Huzaifa Kapasi, Sr. Architect, FullStack Datascientist\n",
    "\n",
    "#### Note - Read the article first to understand the implied concepts behind Laplacian Score.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a80ed524",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "from scipy.sparse import *\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "07ef670e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class feature_selector_laplace():\n",
    "    \n",
    "    def __init__(self, filename):\n",
    "        \n",
    "        self.filename =filename\n",
    "        \n",
    "    def load_data(self):\n",
    "        \n",
    "        mat = scipy.io.loadmat(self.filename)\n",
    "        self.X=mat['X']\n",
    "        self.Y= mat['Y']\n",
    "        \n",
    "        return self.X,self.Y\n",
    "        \n",
    "        \n",
    "\n",
    "    def laplacian_score(self,X,W):\n",
    "            \n",
    "            \n",
    "            \"\"\" Input - X: input data        \n",
    "            W: input affinity matrix\n",
    "            Output -score: laplacian score for each feature\n",
    "            Reference- He, Xiaofei et al. \"Laplacian Score for Feature Selection.\" NIPS 2005.\n",
    "                       Li, Jundong - ACM Computing Surveys (CSUR) Journal\n",
    "            \"\"\"\n",
    "            # build the diagonal D matrix from affinity matrix W\n",
    "            D = np.array(W.sum(axis=1))\n",
    "            L = W\n",
    "            tmp = np.dot(np.transpose(D), X)\n",
    "            D = diags(np.transpose(D), [0])\n",
    "            Xt = np.transpose(X)\n",
    "            t1 = np.transpose(np.dot(Xt, D.todense()))\n",
    "            t2 = np.transpose(np.dot(Xt, L.todense()))\n",
    "    \n",
    "            # compute the numerator of Lr\n",
    "            D_prime = np.sum(np.multiply(t1, X), 0) - np.multiply(tmp, tmp)/D.sum()\n",
    "    \n",
    "            # compute the denominator of Lr\n",
    "            L_prime = np.sum(np.multiply(t2, X), 0) - np.multiply(tmp, tmp)/D.sum()\n",
    "    \n",
    "            # avoid the denominator of Lr to be 0\n",
    "            D_prime[D_prime < 1e-12] = 10000\n",
    "    \n",
    "            # compute laplacian score for all features\n",
    "            score = 1 - np.array(np.multiply(L_prime, 1/D_prime))[0, :]\n",
    "    \n",
    "            return np.transpose(score)\n",
    "    \n",
    "    \n",
    "    def rank(self,score):\n",
    "    \n",
    "            idx = np.argsort(score, 0)\n",
    "            return idx\n",
    "        \n",
    "    def affinity_W(self,X):\n",
    "            \"\"\"\n",
    "            Construct the affinity matrix W \n",
    "            Input - X: input data\n",
    "            Output -W: output affinity matrix W\n",
    "            \"\"\"\n",
    "            print('affinity_W()')\n",
    "            n_samples, n_features = np.shape(X)\n",
    "            \n",
    "            \n",
    "            k = 20       \n",
    "            #numpy.savetxt(\"test.csv\", X, delimiter=\",\")\n",
    "            # normalize the data first\n",
    "            X_norm = np.power(np.sum(X*X, axis=1), 0.5)\n",
    "           \n",
    "            for i in range(n_samples):\n",
    "                    X[i, :] = X[i, :]/max(1e-12, X_norm[i])\n",
    "           \n",
    "            # compute pairwise cosine distances\n",
    "            # Cosine distance is dot product \n",
    "            D_cosine = np.dot(X, np.transpose(X))\n",
    "            \n",
    "            # sort the distance matrix D in ascending order\n",
    "            dump = np.sort(-D_cosine, axis=1)\n",
    "            idx = np.argsort(-D_cosine, axis=1)\n",
    "            idx_new = idx[:, 0:k+1]\n",
    "            dump_new = -dump[:, 0:k+1]\n",
    "            G = np.zeros((n_samples*(k+1), 3))\n",
    "            G[:, 0] = np.tile(np.arange(n_samples), (k+1, 1)).reshape(-1)\n",
    "            G[:, 1] = np.ravel(idx_new, order='F')\n",
    "            G[:, 2] = np.ravel(dump_new, order='F')\n",
    "            \n",
    "            # build the sparse affinity matrix W\n",
    "    \n",
    "            W = csc_matrix((G[:, 2], (G[:, 0], G[:, 1])), shape=(n_samples, n_samples))\n",
    "            bigger = np.transpose(W) > W\n",
    "            W = W - W.multiply(bigger) + np.transpose(W).multiply(bigger)\n",
    "            return W\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "06bc48e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "affinity_W()\n",
      "[[27.16380936 27.16675861 27.17627594 ... 28.16380936 28.16380936\n",
      "  28.16380936]\n",
      " [29.8394775  29.83652825 29.84196036 ... 30.83652825 30.83652825\n",
      "  30.83652825]\n",
      " [34.16281382 34.15577935 34.15034724 ... 35.15034724 35.15034724\n",
      "  35.15034724]\n",
      " ...\n",
      " [20.05788142 20.05788142 20.05788142 ... 19.05788142 19.07404329\n",
      "  19.08730127]\n",
      " [20.07769454 20.07769454 20.07769454 ... 19.09385641 19.07769454\n",
      "  19.09947886]\n",
      " [20.0738987  20.0738987  20.0738987  ... 19.10331854 19.09568302\n",
      "  19.0738987 ]]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'matrix' object has no attribute 'todense'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[1;32mIn [27]\u001b[0m, in \u001b[0;36m<cell line: 8>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m X,Y\u001b[38;5;241m=\u001b[39mfsl\u001b[38;5;241m.\u001b[39mload_data()\n\u001b[0;32m      7\u001b[0m W \u001b[38;5;241m=\u001b[39m fsl\u001b[38;5;241m.\u001b[39maffinity_W(X)\n\u001b[1;32m----> 8\u001b[0m score \u001b[38;5;241m=\u001b[39m \u001b[43mfsl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlaplacian_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43mW\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m score_ranked \u001b[38;5;241m=\u001b[39m fsl\u001b[38;5;241m.\u001b[39mrank(score)\n",
      "Input \u001b[1;32mIn [26]\u001b[0m, in \u001b[0;36mfeature_selector_laplace.laplacian_score\u001b[1;34m(self, X, W)\u001b[0m\n\u001b[0;32m     32\u001b[0m Xt \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mtranspose(X)\n\u001b[0;32m     33\u001b[0m t1 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mtranspose(np\u001b[38;5;241m.\u001b[39mdot(Xt, D\u001b[38;5;241m.\u001b[39mtodense()))\n\u001b[1;32m---> 34\u001b[0m t2 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mtranspose(np\u001b[38;5;241m.\u001b[39mdot(Xt, \u001b[43mL\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtodense\u001b[49m()))\n\u001b[0;32m     36\u001b[0m \u001b[38;5;66;03m# compute the numerator of Lr\u001b[39;00m\n\u001b[0;32m     37\u001b[0m D_prime \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msum(np\u001b[38;5;241m.\u001b[39mmultiply(t1, X), \u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m-\u001b[39m np\u001b[38;5;241m.\u001b[39mmultiply(tmp, tmp)\u001b[38;5;241m/\u001b[39mD\u001b[38;5;241m.\u001b[39msum()\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'matrix' object has no attribute 'todense'"
     ]
    }
   ],
   "source": [
    "path = r\"C:\\Users\\huzaifa_kapasi\\Documents\\inter\\Laplace_Feature\\COIL20.mat\"\n",
    "\n",
    "fsl=feature_selector_laplace(path)\n",
    "X,Y=fsl.load_data()\n",
    "\n",
    "\n",
    "W = fsl.affinity_W(X)\n",
    "score = fsl.laplacian_score(X,W)\n",
    "score_ranked = fsl.rank(score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8d03d9a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 510  478  542  445  477  446  509  413  476  444  541  574  412  482\n",
      "  514  508  573  867  546  381  450  449  540  380  414  418  513  835\n",
      "  174  838  802  605  481  419  578  387 1001  451  417  206  572  474\n",
      "  606  770  511  386  806  483  579  969  198  442  604  547  545  968\n",
      "  834  475  637  506  515  936 1002  443  543  538  737   10  411  480\n",
      "  899  230  738  173  217  410  512  216  135    9  611  610  507  804\n",
      "  420  705  970  184  741  348  249  707  706  636  846  379  845  774\n",
      "  142  709  355  674  388  814   41  207  539  141  175  772  937  903\n",
      "  378  877  935  577  385  739  642  773  803  349  870  479  143  901\n",
      "  108   75  354  908  813  166  964  167  452   76  570  422  571  390\n",
      "  109  742  932   72  580  836  389   42  347  152  940  740  997  638\n",
      "  131  668  938  456  205  609  151  871  669  185   73  939  782  421\n",
      "  900  868  448  409   43  805  328  356  673  544  112  327  603   40\n",
      "  424  441  454  775  488  183  548  382  602  520  771  837  971  876\n",
      "  248  295  869  392  612  473  807  878  839  360  218   77  377  552\n",
      "  144  316  250  346  641  215   74  769  643  113  675  238  290  353\n",
      "  140  315  358  708  258  635  677  909  115  199  231   82  226  194\n",
      "  904  357  239  107  103  100  104  145   44  111  486  584  296  163\n",
      "  281  907  262  291  965  359  576  550  505  345  176  147  214   81\n",
      "  110  710  229  711   80  182  180  114  261   68  518  146  743  247\n",
      "  150    6  484  440  263  313  575  941  416  148  259  197  453  613\n",
      "  844  106  616  783  472  246  314  582  455  228  879  423  815  634\n",
      "  679  293  537  177  645  168  840  667  408  257  516  549  105  504\n",
      "  931  825  138  517  213  260  581  376  325  648  179  781  487  700\n",
      "  283  251  972  847  912   99  282  136  322  866  536  208  644  294\n",
      "  101  680  284   37 1000  793   83  329  172  289   11  391  149  119\n",
      "  966  905  361  118  824  873  485  551  519   49   79  998  212 1003\n",
      "  200  317  911  181  280  169  647  393  137  856  614  569  178  326\n",
      "  848  196  808  615  245  608  872  264  568  701  699  601  906  244\n",
      "  227  117  776  880  823  219  323  116  678  583  874  854  841  967\n",
      "  425  162  292  910  297  344  822  666  676   46  279  232  934  225\n",
      "  944  855  312  240  237  209  311   47  211  195  132  170  210  794\n",
      "   84   78  252  913  712  321   45  943  384  857  139  134  820  852\n",
      "  600  457  816  791   50   48  265  731  875  946  945  633  670   71\n",
      "  784   36  646  886  826  883  974  153  375  792   85  165  790  902\n",
      "  942  278  881  732  744  809  914  447  842  817  888  812  761  851\n",
      "  171  849  585  407   86  496  186  843  915  632    8  343  887  120\n",
      "  885  617  821  698  164  853  592  882  973  975  201  933  649  464\n",
      "  818  751  750  560  553  528  819  665  439  789  884  285  788  640\n",
      "  729    5  795  624  681  810  243  432   87  977  763  502  324  730\n",
      "   69  202  471  133  719  664  470  762  999  850  503   70   51  976\n",
      "  687  759  489   38  697  438  220  233  787  534   39  310  271  978\n",
      "  801  733  917   52  760  727  918  777  400  277  130  764  535  713\n",
      "  796  656  827  521  947  728   16  276    7  916  567  979  204  919\n",
      "  785  778  350  696  948  758  752   53  406  241  566  374  253  655\n",
      "  672  599  234  203  786  757  745  949  102  811  980 1007  266  688\n",
      "  270  720  631 1008   15  663  242  187   54  695 1006  756  342  272\n",
      "  858  950   12  726  598  352  309  889  368   67  607   88  780  920\n",
      "  298 1004  828   14  394  308  746  765  303  725  367  630  121  373\n",
      "  236  623  335  362  981   55   17 1009  193  154  797  951  273  704\n",
      "  405  341  724  235  662   13  694 1005  779  275  330  304  661  755\n",
      "  714  305  426  597  629  336  702  437  399  859  469  753  898  458\n",
      "   20  693 1011  533  501  459   21  565 1010  188  591  718  320  221\n",
      "  431  427  318  890  754   89  982 1012   19  721  363  395  559  463\n",
      "  269  267  274  952  495  155   56  340  490  491  122 1023    0 1022\n",
      "  527  921   30  337  302  983   22   18  288  692   31  860  722  415\n",
      "  286   90  682  554  749  123  747  523  555  586  307  829  331  522\n",
      "  306  723  156  689  833  434  124 1013  734  402  587  891  922  466\n",
      "  748  369   91  338  372  953  366  498  618  370  650  460  594  690\n",
      "  660  530  401  984  398   57  626  562   98   63  657  766  268  992\n",
      "  492  189  428  157  396  923  158  658  619  254  334  256  430  433\n",
      "   23  625  299  736  963  125  954  996  524  465  990  991  639  892\n",
      "  497  686  494 1014  364  222  628  691  526 1021  339  462  404  798\n",
      "  651   92  593   58  529  959  556  561  190  683  332  715  301  654\n",
      "  161  300  861  558  493  461  622  588  590  595  924  659  893  985\n",
      "  531  371  467  627  429  126   93  499  436  563 1015  525  435  955\n",
      "  596  397  830  403  557  862  589  620   59  383  468   24  717  621\n",
      "  365  333   32  716  564  986  652  925  500 1016  532  684  224  351\n",
      "  894  671  653   35  319  956  287  223  685  191   95   25  255   60\n",
      "  930   29  768 1017  159  703   94  993   26  735    4  767  865  957\n",
      "  987  799   66  926  927  129  831   61 1018    1   27  994  960  995\n",
      "  863  192  127 1020  800    3  988  958 1019   28  962   97  895   34\n",
      "  897   62  928    2   65  989  929  160   96  832   64   33  864  896\n",
      "  128  961]\n"
     ]
    }
   ],
   "source": [
    "print(score_ranked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5970f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def laplacian_score(self,X,W):\n",
    "            \n",
    "            \n",
    "    \"\"\" Input - X: input data        \n",
    "    W: input affinity matrix\n",
    "    Output -score: laplacian score for each feature\n",
    "    Reference- He, Xiaofei et al. \"Laplacian Score for Feature Selection.\" NIPS 2005.\n",
    "               Li, Jundong - ACM Computing Surveys (CSUR) Journal\n",
    "    \"\"\"\n",
    "    # build the diagonal D matrix from affinity matrix W\n",
    "    D = np.array(W.sum(axis=1))\n",
    "    L = W\n",
    "    tmp = np.dot(np.transpose(D), X)\n",
    "    D = diags(np.transpose(D), [0])\n",
    "    Xt = np.transpose(X)\n",
    "    t1 = np.transpose(np.dot(Xt, D.todense()))\n",
    "    t2 = np.transpose(np.dot(Xt, L.todense()))\n",
    "    \n",
    "    # compute the numerator of Lr\n",
    "    D_prime = np.sum(np.multiply(t1, X), 0) - np.multiply(tmp, tmp)/D.sum()\n",
    "    \n",
    "    # compute the denominator of Lr\n",
    "    L_prime = np.sum(np.multiply(t2, X), 0) - np.multiply(tmp, tmp)/D.sum()\n",
    "    \n",
    "    # avoid the denominator of Lr to be 0\n",
    "    D_prime[D_prime < 1e-12] = 10000\n",
    "    \n",
    "    # compute laplacian score for all features\n",
    "    score = 1 - np.array(np.multiply(L_prime, 1/D_prime))[0, :]\n",
    "    \n",
    "    return np.transpose(score)\n",
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
